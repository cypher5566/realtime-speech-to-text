#!/usr/bin/env python3
"""
ğŸ™ï¸ Google Cloud Speech-to-Text V2 é€£çºŒå¯¦æ™‚è½‰éŒ„
æ”¯æŒç„¡é™æ™‚é•·éŒ„éŸ³ï¼Œè‡ªå‹•è™•ç† 5 åˆ†é˜æµå¼é™åˆ¶
"""

import os
import sys
import json
import threading
import time
from queue import Queue
import pyaudio
import re
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech

# è¨­ç½®ç’°å¢ƒè®Šé‡
os.environ['GOOGLE_CLOUD_PROJECT'] = 'lithe-window-713'

# éŸ³é »åƒæ•¸
RATE = 16000
CHUNK = int(RATE / 10)  # 100ms ç·©è¡
FORMAT = pyaudio.paInt16
CHANNELS = 1

# é¡è‰²ä»£ç¢¼
class Colors:
    GREY = '\033[90m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

def load_custom_vocabulary():
    """è¼‰å…¥è‡ªå®šç¾©è©å½™"""
    try:
        with open('custom_vocabulary.json', 'r', encoding='utf-8') as f:
            vocab_data = json.load(f)
        
        phrases = []
        count = 0
        for category, terms in vocab_data.items():
            phrases.extend(terms)
            count += len(terms)
        
        print(f"ğŸ“š è¼‰å…¥ {count} å€‹è‡ªå®šç¾©è©å½™")
        if count > 0:
            print(f"ğŸš€ å•Ÿç”¨è©å½™é©æ‡‰æ€§åŠŸèƒ½ï¼Œæå‡å°ˆæ¥­è¡“èªè­˜åˆ¥æº–ç¢ºåº¦")
            print(f"ğŸ“ è¼‰å…¥çš„è©å½™åŒ…æ‹¬:")
            # é¡¯ç¤ºå‰ 10 å€‹è©å½™
            displayed = phrases[:10]
            for term in displayed:
                print(f"   â€¢ {term}")
            if count > 10:
                print(f"   ... é‚„æœ‰ {count - 10} å€‹")
        
        return phrases
    except FileNotFoundError:
        print("ğŸ“ æœªæ‰¾åˆ°è‡ªå®šç¾©è©å½™æª”æ¡ˆï¼Œä½¿ç”¨é è¨­è¨­å®š")
        return []
    except Exception as e:
        print(f"âš ï¸ è¼‰å…¥è©å½™æ™‚å‡ºéŒ¯: {e}")
        return []

def fix_capitalization(text, custom_phrases):
    """ä¿®æ­£æ–‡å­—ä¸­å°ˆæœ‰åè©çš„å¤§å°å¯«"""
    if not custom_phrases:
        return text
    
    result = text
    
    # ç‚ºæ¯å€‹è‡ªå®šç¾©è©å½™é€²è¡Œå¤§å°å¯«ä¿®æ­£
    for phrase in custom_phrases:
        # å‰µå»ºä¸å€åˆ†å¤§å°å¯«çš„æœå°‹æ¨¡å¼
        # ä½¿ç”¨å–®è©é‚Šç•Œä¾†ç¢ºä¿å®Œæ•´åŒ¹é…ï¼Œä½†å…è¨±ä¸€äº›æ¨™é»ç¬¦è™Ÿ
        words = phrase.split()
        
        if len(words) == 1:
            # å–®è©åŒ¹é…ï¼šä½¿ç”¨å–®è©é‚Šç•Œ
            pattern = r'\b' + re.escape(phrase.lower()) + r'\b'
        else:
            # å¤šè©åŒ¹é…ï¼šæ›´éˆæ´»çš„åŒ¹é…
            pattern = r'\b' + r'\s+'.join(re.escape(word.lower()) for word in words) + r'\b'
        
        def replace_func(match):
            return phrase  # è¿”å›æ­£ç¢ºçš„å¤§å°å¯«ç‰ˆæœ¬
        
        # ä¸å€åˆ†å¤§å°å¯«çš„æ›¿æ›
        result = re.sub(pattern, replace_func, result, flags=re.IGNORECASE)
    
    return result

class AudioStreamer:
    """éŸ³é »æµè™•ç†å™¨"""
    
    def __init__(self):
        self.audio_queue = Queue()
        self.should_stop = False
        self.stream = None
        self.audio_interface = None
        
    def start_recording(self):
        """é–‹å§‹éŒ„éŸ³"""
        self.audio_interface = pyaudio.PyAudio()
        
        # æŸ¥æ‰¾éº¥å…‹é¢¨
        print("ğŸ¤ æœå°‹å¯ç”¨çš„éº¥å…‹é¢¨...")
        for i in range(self.audio_interface.get_device_count()):
            info = self.audio_interface.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                print(f"   ğŸ“± {info['name']} (è¼¸å…¥è²é“: {info['maxInputChannels']})")
        
        try:
            self.stream = self.audio_interface.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
                stream_callback=self._audio_callback
            )
            
            device_info = self.audio_interface.get_device_info_by_index(self.stream._input_device_id)
            print(f"âœ… ä½¿ç”¨éº¥å…‹é¢¨: {device_info['name']}")
            print(f"ğŸ¤ é–‹å§‹éŒ„éŸ³...")
            
            self.stream.start_stream()
            return True
            
        except Exception as e:
            print(f"âŒ éŒ„éŸ³å¤±æ•—: {e}")
            return False
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """éŸ³é »å›èª¿å‡½æ•¸"""
        if not self.should_stop:
            self.audio_queue.put(in_data)
        return (None, pyaudio.paContinue)
    
    def get_audio_generator(self):
        """éŸ³é »æ•¸æ“šç”Ÿæˆå™¨"""
        while not self.should_stop:
            try:
                chunk = self.audio_queue.get(timeout=1.0)
                # ç¢ºä¿éŸ³é »å¡Šå¤§å°ä¸è¶…é 25600 å­—ç¯€
                max_chunk_size = 25600
                if len(chunk) > max_chunk_size:
                    # åˆ†å‰²å¤§å¡Š
                    for i in range(0, len(chunk), max_chunk_size):
                        yield chunk[i:i + max_chunk_size]
                else:
                    yield chunk
            except:
                continue
    
    def stop_recording(self):
        """åœæ­¢éŒ„éŸ³"""
        self.should_stop = True
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        if self.audio_interface:
            self.audio_interface.terminate()

class ContinuousTranscriber:
    """é€£çºŒè½‰éŒ„å™¨ - è‡ªå‹•è™•ç†5åˆ†é˜é™åˆ¶"""
    
    def __init__(self):
        self.client = SpeechClient()
        self.audio_streamer = AudioStreamer()
        self.should_stop = False
        self.session_count = 0
        
    def create_recognition_config(self, phrases):
        """å‰µå»ºè­˜åˆ¥é…ç½®"""
        # è©å½™é©æ‡‰é…ç½®
        adaptation = None
        if phrases:
            phrase_set = cloud_speech.PhraseSet()
            for phrase in phrases:
                phrase_set.phrases.append(cloud_speech.PhraseSet.Phrase(value=phrase, boost=10.0))
            
            adaptation = cloud_speech.SpeechAdaptation()
            adaptation.phrase_sets.append(phrase_set)
        
        # è­˜åˆ¥é…ç½®
        recognition_config = cloud_speech.RecognitionConfig(
            explicit_decoding_config=cloud_speech.ExplicitDecodingConfig(
                encoding=cloud_speech.ExplicitDecodingConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=RATE,
                audio_channel_count=CHANNELS,
            ),
            language_codes=["en-US"],  # æ”¯æŒçš„èªè¨€
            model="chirp_2",
            features=cloud_speech.RecognitionFeatures(
                enable_automatic_punctuation=True,
                enable_word_time_offsets=False,
                max_alternatives=1,
            ),
        )
        
        if adaptation:
            recognition_config.adaptation = adaptation
            
        return recognition_config
    
    def single_stream_session(self, recognition_config):
        """å–®æ¬¡æµå¼æœƒè©±ï¼ˆæœ€å¤š5åˆ†é˜ï¼‰"""
        self.session_count += 1
        session_start_time = time.time()
        
        print(f"\n{Colors.CYAN}ğŸ”„ å•Ÿå‹•æœƒè©± #{self.session_count}{Colors.END}")
        print(f"{Colors.YELLOW}â±ï¸ æ­¤æœƒè©±æœ€å¤šæŒçºŒ 5 åˆ†é˜{Colors.END}")
        
        # æµå¼è­˜åˆ¥é…ç½®
        streaming_config = cloud_speech.StreamingRecognitionConfig(
            config=recognition_config,
            streaming_features=cloud_speech.StreamingRecognitionFeatures(
                interim_results=True,
                voice_activity_timeout=cloud_speech.StreamingRecognitionFeatures.VoiceActivityTimeout(
                    speech_start_timeout=15,
                    speech_end_timeout=15,
                ),
            ),
        )
        
        def request_generator():
            """ç”Ÿæˆè­˜åˆ¥è«‹æ±‚"""
            # ç¬¬ä¸€å€‹è«‹æ±‚åŒ…å«é…ç½®
            yield cloud_speech.StreamingRecognizeRequest(
                recognizer=f"projects/{os.environ['GOOGLE_CLOUD_PROJECT']}/locations/us-central1/recognizers/_",
                streaming_config=streaming_config,
            )
            
            # å¾ŒçºŒè«‹æ±‚åŒ…å«éŸ³é »æ•¸æ“š
            for chunk in self.audio_streamer.get_audio_generator():
                if self.should_stop:
                    break
                    
                # æª¢æŸ¥æ˜¯å¦æ¥è¿‘5åˆ†é˜é™åˆ¶
                if time.time() - session_start_time > 280:  # 4åˆ†40ç§’
                    print(f"\n{Colors.YELLOW}âš ï¸ æ¥è¿‘5åˆ†é˜é™åˆ¶ï¼Œæº–å‚™é‡æ–°é€£æ¥...{Colors.END}")
                    break
                    
                yield cloud_speech.StreamingRecognizeRequest(audio=chunk)
        
        try:
            responses = self.client.streaming_recognize(requests=request_generator())
            self.process_responses(responses)
            
        except Exception as e:
            if "Max duration of 5 minutes" in str(e):
                print(f"\n{Colors.YELLOW}â±ï¸ æœƒè©± #{self.session_count} é”åˆ°5åˆ†é˜é™åˆ¶{Colors.END}")
            else:
                print(f"\n{Colors.RED}âŒ æœƒè©± #{self.session_count} éŒ¯èª¤: {e}{Colors.END}")
    
    def process_responses(self, responses):
        """è™•ç†è­˜åˆ¥éŸ¿æ‡‰"""
        last_interim_length = 0
        
        # è¼‰å…¥è©å½™ç”¨æ–¼å¤§å°å¯«ä¿®æ­£
        custom_phrases = load_custom_vocabulary()
        
        try:
            for response in responses:
                if self.should_stop:
                    break
                    
                for result in response.results:
                    if result.alternatives:
                        transcript = result.alternatives[0].transcript.strip()
                        
                        if result.is_final:
                            # æœ€çµ‚çµæœ - ç¶ è‰²ï¼Œå…ˆä¿®æ­£å¤§å°å¯«å†é¡¯ç¤º
                            corrected_transcript = fix_capitalization(transcript, custom_phrases)
                            
                            clear_chars = max(0, last_interim_length - len(corrected_transcript) - 3)
                            overwrite_chars = " " * clear_chars
                            
                            print(f"\r{Colors.GREEN}âœ… {corrected_transcript}{Colors.END}{overwrite_chars}")
                            print("-" * 60)
                            last_interim_length = 0
                        else:
                            # ä¸­é–“çµæœ - ç°è‰²ï¼Œè¦†è“‹ä¹‹å‰çš„å…§å®¹
                            # è¨ˆç®—éœ€è¦æ¸…é™¤çš„å­—ç¬¦æ•¸é‡
                            clear_chars = max(0, last_interim_length - len(transcript) - 3)
                            overwrite_chars = " " * clear_chars
                            
                            print(f"\r{Colors.GREY}ğŸ”˜ {transcript}{Colors.END}{overwrite_chars}", end='', flush=True)
                            
                            # è¨˜éŒ„ç•¶å‰è¡Œçš„é•·åº¦ï¼ˆåŒ…æ‹¬emojiå’Œå‰ç¶´ï¼‰
                            last_interim_length = len(transcript) + 3
                            
        except Exception as e:
            if "Max duration of 5 minutes" not in str(e):
                print(f"\n{Colors.RED}âŒ è™•ç†éŸ¿æ‡‰éŒ¯èª¤: {e}{Colors.END}")
    
    def start_continuous_transcription(self):
        """é–‹å§‹é€£çºŒè½‰éŒ„"""
        print(f"{Colors.BOLD}{Colors.BLUE}ğŸ™ï¸  Google Cloud Speech-to-Text V2 é€£çºŒå¯¦æ™‚è½‰éŒ„{Colors.END}")
        print("=" * 60)
        print(f"ğŸ“ é …ç›®: {os.environ['GOOGLE_CLOUD_PROJECT']}")
        print(f"ğŸš€ ä½¿ç”¨ Chirp 2 æ¨¡å‹é€²è¡Œé€£çºŒèªéŸ³è­˜åˆ¥")
        print(f"â±ï¸ è‡ªå‹•è™•ç† 5 åˆ†é˜æµå¼é™åˆ¶")
        print(f"ğŸ“ æŒ‰ Ctrl+C åœæ­¢")
        print("=" * 60)
        
        # è¼‰å…¥è‡ªå®šç¾©è©å½™
        phrases = load_custom_vocabulary()
        recognition_config = self.create_recognition_config(phrases)
        
        # é–‹å§‹éŒ„éŸ³
        if not self.audio_streamer.start_recording():
            return
        
        print(f"âœ… é€£æ¥æˆåŠŸï¼Œé–‹å§‹é€£çºŒè½‰éŒ„:")
        print("-" * 60)
        print(f"ğŸ’¡ èªªè©±æç¤º:")
        print(f"   ğŸ”˜ ç°è‰² = æ­£åœ¨è­˜åˆ¥")
        print(f"   âœ… ç¶ è‰² = ç¢ºèªçµæœ")
        print(f"   ğŸ”„ è—è‰² = æœƒè©±é‡é€£")
        print("-" * 60)
        
        try:
            while not self.should_stop:
                # å•Ÿå‹•æ–°çš„5åˆ†é˜æœƒè©±
                self.single_stream_session(recognition_config)
                
                if not self.should_stop:
                    print(f"\n{Colors.CYAN}ğŸ”„ è‡ªå‹•é‡æ–°é€£æ¥... (æœƒè©± #{self.session_count + 1}){Colors.END}")
                    time.sleep(1)  # çŸ­æš«å»¶é²
                    
        except KeyboardInterrupt:
            print(f"\n\n{Colors.YELLOW}â¹ï¸ ç”¨æˆ¶åœæ­¢è½‰éŒ„{Colors.END}")
        except Exception as e:
            print(f"\n{Colors.RED}âŒ è½‰éŒ„éŒ¯èª¤: {e}{Colors.END}")
        finally:
            self.stop()
    
    def stop(self):
        """åœæ­¢è½‰éŒ„"""
        self.should_stop = True
        self.audio_streamer.stop_recording()
        print(f"\n{Colors.GREEN}âœ… è½‰éŒ„å·²åœæ­¢{Colors.END}")
        print(f"ğŸ“Š ç¸½æœƒè©±æ•¸: {self.session_count}")

def main():
    """ä¸»å‡½æ•¸"""
    try:
        transcriber = ContinuousTranscriber()
        transcriber.start_continuous_transcription()
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}ğŸ‘‹ å†è¦‹ï¼{Colors.END}")
    except Exception as e:
        print(f"{Colors.RED}âŒ æ‡‰ç”¨ç¨‹åºéŒ¯èª¤: {e}{Colors.END}")
        sys.exit(1)

if __name__ == "__main__":
    main() 