#!/usr/bin/env python3
"""
Google Cloud Speech-to-Text V2 å¯¦æ™‚è½‰éŒ„ + Gemini ç¿»è­¯
åŸºæ–¼ç©©å®šç‰ˆæœ¬ï¼ŒåªåŠ ä¸Šç¿»è­¯åŠŸèƒ½
"""

import os
import queue
import sys
import threading
import time
from queue import Queue

from google.api_core.client_options import ClientOptions
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech
import pyaudio
from custom_vocabulary import get_phrases_for_recognition
import re
import google.generativeai as genai

# è¨­å®š Gemini API
genai.configure(api_key="AIzaSyDwpLELMwSRSEqjSRtOp2F77l61p5caMZE")

# éŸ³é »åƒæ•¸
RATE = 16000
CHUNK = int(RATE / 10)  # 100ms

PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT")

class TranslationManager:
    """ç¿»è­¯ç®¡ç†å™¨ - æ™ºèƒ½ç¿»è­¯è§¸ç™¼"""
    
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        self.translation_queue = Queue()
        self.should_stop = False
        self.last_translation_time = 0
        self.min_interval = 2  # æœ€å°ç¿»è­¯é–“éš”ï¼ˆç§’ï¼‰
        
        # å•Ÿå‹•ç¿»è­¯ç·šç¨‹
        self.translation_thread = threading.Thread(target=self._translation_worker)
        self.translation_thread.daemon = True
        self.translation_thread.start()
    
    def should_translate(self, text):
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²ç¿»è­¯"""
        current_time = time.time()
        
        # æ™‚é–“é–“éš”æª¢æŸ¥
        if current_time - self.last_translation_time < self.min_interval:
            return False
        
        # é•·åº¦æª¢æŸ¥ï¼ˆé™ä½åˆ°20å€‹å­—ç¬¦ï¼‰
        if len(text.strip()) < 20:
            return False
        
        # å¥å­çµå°¾æª¢æŸ¥æˆ–é•·å¥å­ï¼ˆæ”¾å¯¬æ¢ä»¶ï¼‰
        text_clean = text.strip()
        has_ending = any(text_clean.endswith(ending) for ending in ['.', '!', '?', ';'])
        is_long_enough = len(text_clean) >= 25  # 25å­—ç¬¦ä»¥ä¸Šå°±ç¿»è­¯
        
        return has_ending or is_long_enough
    
    def add_text(self, text):
        """æ·»åŠ æ–‡å­—åˆ°ç¿»è­¯éšŠåˆ—"""
        if self.should_translate(text):
            self.translation_queue.put(text)
            self.last_translation_time = time.time()
    
    def _translation_worker(self):
        """ç¿»è­¯å·¥ä½œç·šç¨‹"""
        while not self.should_stop:
            try:
                text = self.translation_queue.get(timeout=1.0)
                if text and text.strip():
                    translation = self._translate(text)
                    if translation:
                        print(f"ğŸŒ \033[95m{translation}\033[0m")
                        print("-" * 60)
            except:
                continue
    
    def _translate(self, text):
        """ä½¿ç”¨ Gemini ç¿»è­¯æ–‡å­—"""
        try:
            prompt = f"è«‹å°‡ä»¥ä¸‹è‹±æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œåªè¦ä¸€å€‹æœ€ä½³ç¿»è­¯çµæœï¼Œä¸è¦è§£é‡‹ï¼š{text}"
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"ç¿»è­¯éŒ¯èª¤: {e}")
            return None
    
    def stop(self):
        """åœæ­¢ç¿»è­¯æœå‹™"""
        self.should_stop = True

# å…¨å±€ç¿»è­¯ç®¡ç†å™¨
translator = TranslationManager()

def fix_capitalization(text, custom_phrases):
    """ä¿®æ­£æ–‡å­—ä¸­å°ˆæœ‰åè©çš„å¤§å°å¯«"""
    if not custom_phrases:
        return text
    
    result = text
    
    # ç‚ºæ¯å€‹è‡ªå®šç¾©è©å½™é€²è¡Œå¤§å°å¯«ä¿®æ­£
    for phrase in custom_phrases:
        # å‰µå»ºä¸å€åˆ†å¤§å°å¯«çš„æœå°‹æ¨¡å¼
        # ä½¿ç”¨å–®è©é‚Šç•Œä¾†ç¢ºä¿å®Œæ•´åŒ¹é…ï¼Œä½†å…è¨±ä¸€äº›æ¨™é»ç¬¦è™Ÿ
        words = phrase.split()
        
        if len(words) == 1:
            # å–®è©åŒ¹é…ï¼šä½¿ç”¨å–®è©é‚Šç•Œ
            pattern = r'\b' + re.escape(phrase.lower()) + r'\b'
        else:
            # å¤šè©åŒ¹é…ï¼šæ›´éˆæ´»çš„åŒ¹é…
            pattern = r'\b' + r'\s+'.join(re.escape(word.lower()) for word in words) + r'\b'
        
        def replace_func(match):
            return phrase  # è¿”å›æ­£ç¢ºçš„å¤§å°å¯«ç‰ˆæœ¬
        
        # ä¸å€åˆ†å¤§å°å¯«çš„æ›¿æ›
        result = re.sub(pattern, replace_func, result, flags=re.IGNORECASE)
    
    return result

class MicrophoneStream:
    """éº¥å…‹é¢¨éŸ³é »æµé¡"""
    
    def __init__(self, rate=RATE, chunk=CHUNK):
        self._rate = rate
        self._chunk = chunk
        self._buff = queue.Queue()
        self.closed = True

    def __enter__(self):
        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self._rate,
            input=True,
            frames_per_buffer=self._chunk,
            stream_callback=self._fill_buffer,
        )
        self.closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)
        self._audio_interface.terminate()

    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):
        """å°‡éŸ³é »æ•¸æ“šæ”¾å…¥ç·©è¡å€"""
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        """éŸ³é »æ•¸æ“šç”Ÿæˆå™¨ - é™åˆ¶éŸ³é »å¡Šå¤§å°"""
        MAX_CHUNK_SIZE = 25600  # Google Cloud é™åˆ¶ (25KB)
        
        while not self.closed:
            chunk = self._buff.get()
            if chunk is None:
                return
            
            # ç›´æ¥ç™¼é€å–®å€‹å¡Šï¼Œé¿å…ç´¯ç©éå¤šæ•¸æ“š
            if len(chunk) <= MAX_CHUNK_SIZE:
                yield chunk
            else:
                # å¦‚æœå–®å€‹å¡Šå¤ªå¤§ï¼Œåˆ†å‰²å®ƒ
                for i in range(0, len(chunk), MAX_CHUNK_SIZE):
                    yield chunk[i:i+MAX_CHUNK_SIZE]


def transcribe_streaming_v2():
    """ä½¿ç”¨ Speech v2 é€²è¡Œå¯¦æ™‚è½‰éŒ„ + Gemini ç¿»è­¯"""
    print("ğŸ™ï¸  Google Cloud Speech-to-Text V2 + Gemini ç¿»è­¯")
    print("=" * 60)
    print(f"ğŸ“ é …ç›®: {PROJECT_ID}")
    print("ğŸš€ ä½¿ç”¨ Chirp 2 æ¨¡å‹é€²è¡Œå¯¦æ™‚èªéŸ³è­˜åˆ¥")
    print("ğŸŒ ä½¿ç”¨ Gemini-2.0-flash-exp æ™ºèƒ½ç¿»è­¯")
    print("ğŸ“ æŒ‰ Ctrl+C åœæ­¢")
    print("=" * 60)

    # å‰µå»ºå®¢æˆ¶ç«¯
    client = SpeechClient(
        client_options=ClientOptions(
            api_endpoint="us-central1-speech.googleapis.com",
        )
    )

    # è¼‰å…¥è‡ªå®šç¾©è©å½™
    custom_phrases = get_phrases_for_recognition()
    
    # é…ç½®è­˜åˆ¥ - æ˜ç¢ºæŒ‡å®šç·¨ç¢¼æ ¼å¼
    recognition_config = cloud_speech.RecognitionConfig(
        explicit_decoding_config=cloud_speech.ExplicitDecodingConfig(
            encoding=cloud_speech.ExplicitDecodingConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            audio_channel_count=1,
        ),
        language_codes=["en-US"],  # ä½¿ç”¨è‹±æ–‡
        model="chirp_2",
    )
    
    # å¦‚æœæœ‰è‡ªå®šç¾©è©å½™ï¼ŒåŠ å…¥ Speech v2 é©æ‡‰æ€§é…ç½®
    if custom_phrases:
        print(f"ğŸ“š è¼‰å…¥ {len(custom_phrases)} å€‹è‡ªå®šç¾©è©å½™")
        print("ğŸš€ å•Ÿç”¨è©å½™é©æ‡‰æ€§åŠŸèƒ½ï¼Œæå‡å°ˆæ¥­è¡“èªè­˜åˆ¥æº–ç¢ºåº¦")
        
        # é¡¯ç¤ºå‰10å€‹è©å½™
        print("ğŸ“ è¼‰å…¥çš„è©å½™åŒ…æ‹¬:")
        for i, phrase in enumerate(custom_phrases[:10]):
            print(f"   â€¢ {phrase}")
        if len(custom_phrases) > 10:
            print(f"   ... é‚„æœ‰ {len(custom_phrases) - 10} å€‹")
        
        # ä½¿ç”¨ Speech v2 çš„æ­£ç¢ºé©æ‡‰æ€§æ ¼å¼
        phrase_set = cloud_speech.PhraseSet(
            phrases=[
                {"value": phrase, "boost": 10.0}
                for phrase in custom_phrases[:100]  # é™åˆ¶æ•¸é‡é¿å…è¶…é™
            ]
        )
        
        recognition_config.adaptation = cloud_speech.SpeechAdaptation(
            phrase_sets=[
                cloud_speech.SpeechAdaptation.AdaptationPhraseSet(
                    inline_phrase_set=phrase_set
                )
            ]
        )

    # æµå¼é…ç½®
    streaming_config = cloud_speech.StreamingRecognitionConfig(
        config=recognition_config,
        streaming_features=cloud_speech.StreamingRecognitionFeatures(
            interim_results=True,  # å•Ÿç”¨ä¸­é–“çµæœ
        )
    )

    # å‰µå»ºåˆå§‹è«‹æ±‚
    config_request = cloud_speech.StreamingRecognizeRequest(
        recognizer=f"projects/{PROJECT_ID}/locations/us-central1/recognizers/_",
        streaming_config=streaming_config,
    )

    def requests_generator(config_request, audio_generator):
        """è«‹æ±‚ç”Ÿæˆå™¨ - æŒ‰ç…§å®˜æ–¹æ–‡æª”æ ¼å¼"""
        yield config_request
        for audio_chunk in audio_generator:
            yield cloud_speech.StreamingRecognizeRequest(audio=audio_chunk)

    print("ğŸ¤ é–‹å§‹éŒ„éŸ³...")
    
    try:
        with MicrophoneStream(RATE, CHUNK) as stream:
            audio_generator = stream.generator()
            
            requests = requests_generator(config_request, audio_generator)
            
            # é–‹å§‹æµå¼è­˜åˆ¥
            responses = client.streaming_recognize(requests=requests)
            
            print("âœ… é€£æ¥æˆåŠŸï¼Œé–‹å§‹å¯¦æ™‚è½‰éŒ„:")
            print("-" * 60)
            print("ğŸ’¡ é¡¯ç¤ºèªªæ˜:")
            print("   ğŸ”˜ ç°è‰² = æ­£åœ¨è­˜åˆ¥")
            print("   âœ… ç¶ è‰² = è‹±æ–‡ç¢ºèªçµæœ")
            print("   ğŸŒ ç´«è‰² = ä¸­æ–‡ç¿»è­¯")
            print("-" * 60)
            
            listen_print_loop(responses)
            
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ¶åœæ­¢éŒ„éŸ³")
        translator.stop()
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        translator.stop()
        import traceback
        traceback.print_exc()


def listen_print_loop(responses):
    """è™•ç†ä¸¦é¡¯ç¤ºè½‰éŒ„çµæœ"""
    last_interim_length = 0
    
    # è¼‰å…¥è©å½™ç”¨æ–¼å¤§å°å¯«ä¿®æ­£
    custom_phrases = get_phrases_for_recognition()
    
    for response in responses:
        if not response.results:
            continue

        result = response.results[0]
        if not result.alternatives:
            continue

        transcript = result.alternatives[0].transcript.strip()

        if not result.is_final:
            # ä¸­é–“çµæœ - ç°è‰²ï¼Œè¦†è“‹ä¹‹å‰çš„å…§å®¹
            # è¨ˆç®—éœ€è¦æ¸…é™¤çš„å­—ç¬¦æ•¸é‡
            clear_chars = max(0, last_interim_length - len(transcript) - 3)
            overwrite_chars = " " * clear_chars
            
            sys.stdout.write(f"\rğŸ”˜ \033[90m{transcript}\033[0m{overwrite_chars}")
            sys.stdout.flush()
            
            # è¨˜éŒ„ç•¶å‰è¡Œçš„é•·åº¦ï¼ˆåŒ…æ‹¬emojiå’Œå‰ç¶´ï¼‰
            last_interim_length = len(transcript) + 3
        else:
            # æœ€çµ‚çµæœ - ç¶ è‰²ï¼Œå…ˆä¿®æ­£å¤§å°å¯«å†é¡¯ç¤º
            corrected_transcript = fix_capitalization(transcript, custom_phrases)
            
            clear_chars = max(0, last_interim_length - len(corrected_transcript) - 3)
            overwrite_chars = " " * clear_chars
            
            print(f"\râœ… \033[92m{corrected_transcript}\033[0m{overwrite_chars}")
            
            # å˜—è©¦ç¿»è­¯ï¼ˆæ™ºèƒ½è§¸ç™¼ï¼‰
            translator.add_text(corrected_transcript)
            
            print("-" * 60)
            last_interim_length = 0

            # æª¢æŸ¥é€€å‡ºé—œéµå­—
            if any(word in transcript.lower() for word in ["exit", "quit", "stop"]):
                print("ğŸ‘‹ æª¢æ¸¬åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œåœæ­¢è½‰éŒ„")
                translator.stop()
                break


def main():
    if not PROJECT_ID:
        print("âŒ éŒ¯èª¤: è«‹è¨­ç½® GOOGLE_CLOUD_PROJECT ç’°å¢ƒè®Šé‡")
        print("åŸ·è¡Œ: export GOOGLE_CLOUD_PROJECT=your-project-id")
        return

    transcribe_streaming_v2()


if __name__ == "__main__":
    main() 