#!/usr/bin/env python3
"""
Google Cloud Speech-to-Text V2 å¯¦æ™‚è½‰éŒ„
åŸºæ–¼å®˜æ–¹æ–‡æª”é‡æ–°å¯¦ç¾
"""

import os
import queue
import sys
import threading
import time

from google.api_core.client_options import ClientOptions
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech
import pyaudio
from custom_vocabulary import get_phrases_for_recognition
import re

# éŸ³é »åƒæ•¸
RATE = 16000
CHUNK = int(RATE / 10)  # 100ms

PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT")

def fix_capitalization(text, custom_phrases):
    """ä¿®æ­£æ–‡å­—ä¸­å°ˆæœ‰åè©çš„å¤§å°å¯«"""
    if not custom_phrases:
        return text
    
    result = text
    
    # ç‚ºæ¯å€‹è‡ªå®šç¾©è©å½™é€²è¡Œå¤§å°å¯«ä¿®æ­£
    for phrase in custom_phrases:
        # å‰µå»ºä¸å€åˆ†å¤§å°å¯«çš„æœå°‹æ¨¡å¼
        # ä½¿ç”¨å–®è©é‚Šç•Œä¾†ç¢ºä¿å®Œæ•´åŒ¹é…ï¼Œä½†å…è¨±ä¸€äº›æ¨™é»ç¬¦è™Ÿ
        words = phrase.split()
        
        if len(words) == 1:
            # å–®è©åŒ¹é…ï¼šä½¿ç”¨å–®è©é‚Šç•Œ
            pattern = r'\b' + re.escape(phrase.lower()) + r'\b'
        else:
            # å¤šè©åŒ¹é…ï¼šæ›´éˆæ´»çš„åŒ¹é…
            pattern = r'\b' + r'\s+'.join(re.escape(word.lower()) for word in words) + r'\b'
        
        def replace_func(match):
            return phrase  # è¿”å›æ­£ç¢ºçš„å¤§å°å¯«ç‰ˆæœ¬
        
        # ä¸å€åˆ†å¤§å°å¯«çš„æ›¿æ›
        result = re.sub(pattern, replace_func, result, flags=re.IGNORECASE)
    
    return result

class MicrophoneStream:
    """éº¥å…‹é¢¨éŸ³é »æµé¡"""
    
    def __init__(self, rate=RATE, chunk=CHUNK):
        self._rate = rate
        self._chunk = chunk
        self._buff = queue.Queue()
        self.closed = True

    def __enter__(self):
        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self._rate,
            input=True,
            frames_per_buffer=self._chunk,
            stream_callback=self._fill_buffer,
        )
        self.closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)
        self._audio_interface.terminate()

    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):
        """å°‡éŸ³é »æ•¸æ“šæ”¾å…¥ç·©è¡å€"""
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        """éŸ³é »æ•¸æ“šç”Ÿæˆå™¨ - é™åˆ¶éŸ³é »å¡Šå¤§å°"""
        MAX_CHUNK_SIZE = 25600  # Google Cloud é™åˆ¶ (25KB)
        
        while not self.closed:
            chunk = self._buff.get()
            if chunk is None:
                return
            
            # ç›´æ¥ç™¼é€å–®å€‹å¡Šï¼Œé¿å…ç´¯ç©éå¤šæ•¸æ“š
            if len(chunk) <= MAX_CHUNK_SIZE:
                yield chunk
            else:
                # å¦‚æœå–®å€‹å¡Šå¤ªå¤§ï¼Œåˆ†å‰²å®ƒ
                for i in range(0, len(chunk), MAX_CHUNK_SIZE):
                    yield chunk[i:i+MAX_CHUNK_SIZE]


def transcribe_streaming_v2():
    """ä½¿ç”¨ Speech v2 é€²è¡Œå¯¦æ™‚è½‰éŒ„"""
    print("ğŸ™ï¸  Google Cloud Speech-to-Text V2 å¯¦æ™‚è½‰éŒ„")
    print("=" * 60)
    print(f"ğŸ“ é …ç›®: {PROJECT_ID}")
    print("ğŸš€ ä½¿ç”¨ Chirp 2 æ¨¡å‹é€²è¡Œå¯¦æ™‚èªéŸ³è­˜åˆ¥")
    print("ğŸ“ æŒ‰ Ctrl+C åœæ­¢")
    print("=" * 60)

    # å‰µå»ºå®¢æˆ¶ç«¯
    client = SpeechClient(
        client_options=ClientOptions(
            api_endpoint="us-central1-speech.googleapis.com",
        )
    )

    # è¼‰å…¥è‡ªå®šç¾©è©å½™
    custom_phrases = get_phrases_for_recognition()
    
    # é…ç½®è­˜åˆ¥ - æ˜ç¢ºæŒ‡å®šç·¨ç¢¼æ ¼å¼
    recognition_config = cloud_speech.RecognitionConfig(
        explicit_decoding_config=cloud_speech.ExplicitDecodingConfig(
            encoding=cloud_speech.ExplicitDecodingConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=RATE,
            audio_channel_count=1,
        ),
        language_codes=["en-US"],  # ä½¿ç”¨è‹±æ–‡
        model="chirp_2",
    )
    
    # å¦‚æœæœ‰è‡ªå®šç¾©è©å½™ï¼ŒåŠ å…¥ Speech v2 é©æ‡‰æ€§é…ç½®
    if custom_phrases:
        print(f"ğŸ“š è¼‰å…¥ {len(custom_phrases)} å€‹è‡ªå®šç¾©è©å½™")
        print("ğŸš€ å•Ÿç”¨è©å½™é©æ‡‰æ€§åŠŸèƒ½ï¼Œæå‡å°ˆæ¥­è¡“èªè­˜åˆ¥æº–ç¢ºåº¦")
        
        # é¡¯ç¤ºå‰10å€‹è©å½™
        print("ğŸ“ è¼‰å…¥çš„è©å½™åŒ…æ‹¬:")
        for i, phrase in enumerate(custom_phrases[:10]):
            print(f"   â€¢ {phrase}")
        if len(custom_phrases) > 10:
            print(f"   ... é‚„æœ‰ {len(custom_phrases) - 10} å€‹")
        
        # ä½¿ç”¨ Speech v2 çš„æ­£ç¢ºé©æ‡‰æ€§æ ¼å¼
        phrase_set = cloud_speech.PhraseSet(
            phrases=[
                {"value": phrase, "boost": 10.0}
                for phrase in custom_phrases[:100]  # é™åˆ¶æ•¸é‡é¿å…è¶…é™
            ]
        )
        
        recognition_config.adaptation = cloud_speech.SpeechAdaptation(
            phrase_sets=[
                cloud_speech.SpeechAdaptation.AdaptationPhraseSet(
                    inline_phrase_set=phrase_set
                )
            ]
        )

    # æµå¼é…ç½®
    streaming_config = cloud_speech.StreamingRecognitionConfig(
        config=recognition_config,
        streaming_features=cloud_speech.StreamingRecognitionFeatures(
            interim_results=True,  # å•Ÿç”¨ä¸­é–“çµæœ
        )
    )

    # å‰µå»ºåˆå§‹è«‹æ±‚
    config_request = cloud_speech.StreamingRecognizeRequest(
        recognizer=f"projects/{PROJECT_ID}/locations/us-central1/recognizers/_",
        streaming_config=streaming_config,
    )

    def requests_generator(config_request, audio_generator):
        """è«‹æ±‚ç”Ÿæˆå™¨ - æŒ‰ç…§å®˜æ–¹æ–‡æª”æ ¼å¼"""
        yield config_request
        for audio_chunk in audio_generator:
            yield cloud_speech.StreamingRecognizeRequest(audio=audio_chunk)

    print("ğŸ¤ é–‹å§‹éŒ„éŸ³...")
    
    try:
        with MicrophoneStream(RATE, CHUNK) as stream:
            audio_generator = stream.generator()
            
            requests = requests_generator(config_request, audio_generator)
            
            # é–‹å§‹æµå¼è­˜åˆ¥
            responses = client.streaming_recognize(requests=requests)
            
            print("âœ… é€£æ¥æˆåŠŸï¼Œé–‹å§‹å¯¦æ™‚è½‰éŒ„:")
            print("-" * 60)
            print("ğŸ’¡ èªªè©±æç¤º:")
            print("   ğŸ”˜ ç°è‰² = æ­£åœ¨è­˜åˆ¥")
            print("   âœ… ç¶ è‰² = ç¢ºèªçµæœ")
            print("-" * 60)
            
            listen_print_loop(responses)
            
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ¶åœæ­¢éŒ„éŸ³")
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


def listen_print_loop(responses):
    """è™•ç†ä¸¦é¡¯ç¤ºè½‰éŒ„çµæœ"""
    last_interim_length = 0
    
    # è¼‰å…¥è©å½™ç”¨æ–¼å¤§å°å¯«ä¿®æ­£
    custom_phrases = get_phrases_for_recognition()
    
    for response in responses:
        if not response.results:
            continue

        result = response.results[0]
        if not result.alternatives:
            continue

        transcript = result.alternatives[0].transcript.strip()

        if not result.is_final:
            # ä¸­é–“çµæœ - ç°è‰²ï¼Œè¦†è“‹ä¹‹å‰çš„å…§å®¹
            # è¨ˆç®—éœ€è¦æ¸…é™¤çš„å­—ç¬¦æ•¸é‡
            clear_chars = max(0, last_interim_length - len(transcript) - 3)
            overwrite_chars = " " * clear_chars
            
            sys.stdout.write(f"\rğŸ”˜ \033[90m{transcript}\033[0m{overwrite_chars}")
            sys.stdout.flush()
            
            # è¨˜éŒ„ç•¶å‰è¡Œçš„é•·åº¦ï¼ˆåŒ…æ‹¬emojiå’Œå‰ç¶´ï¼‰
            last_interim_length = len(transcript) + 3
        else:
            # æœ€çµ‚çµæœ - ç¶ è‰²ï¼Œå…ˆä¿®æ­£å¤§å°å¯«å†é¡¯ç¤º
            corrected_transcript = fix_capitalization(transcript, custom_phrases)
            
            clear_chars = max(0, last_interim_length - len(corrected_transcript) - 3)
            overwrite_chars = " " * clear_chars
            
            print(f"\râœ… \033[92m{corrected_transcript}\033[0m{overwrite_chars}")
            print("-" * 60)
            last_interim_length = 0

            # æª¢æŸ¥é€€å‡ºé—œéµå­—
            if any(word in transcript.lower() for word in ["exit", "quit", "stop"]):
                print("ğŸ‘‹ æª¢æ¸¬åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œåœæ­¢è½‰éŒ„")
                break


def main():
    if not PROJECT_ID:
        print("âŒ éŒ¯èª¤: è«‹è¨­ç½® GOOGLE_CLOUD_PROJECT ç’°å¢ƒè®Šé‡")
        print("åŸ·è¡Œ: export GOOGLE_CLOUD_PROJECT=your-project-id")
        return

    transcribe_streaming_v2()


if __name__ == "__main__":
    main() 