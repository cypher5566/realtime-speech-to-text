#!/usr/bin/env python3
"""
è‡ªå®šç¾©è©å½™ç®¡ç†å·¥å…·
ç”¨æ–¼ç®¡ç†èªéŸ³è­˜åˆ¥çš„å°ˆæ¥­è¡“èªè©åº«
"""

import json
import os
from datetime import datetime

VOCABULARY_FILE = "custom_vocabulary.json"

def load_vocabulary():
    """è¼‰å…¥è‡ªå®šç¾©è©å½™"""
    if os.path.exists(VOCABULARY_FILE):
        with open(VOCABULARY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        "phrases": [],
        "categories": {},
        "last_updated": None
    }

def save_vocabulary(vocab_data):
    """å„²å­˜è‡ªå®šç¾©è©å½™"""
    vocab_data["last_updated"] = datetime.now().isoformat()
    with open(VOCABULARY_FILE, 'w', encoding='utf-8') as f:
        json.dump(vocab_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… è©å½™å·²å„²å­˜åˆ° {VOCABULARY_FILE}")

def add_phrase(vocab_data, phrase, category=None):
    """æ–°å¢è©å½™"""
    if phrase not in vocab_data["phrases"]:
        vocab_data["phrases"].append(phrase)
        if category:
            if category not in vocab_data["categories"]:
                vocab_data["categories"][category] = []
            if phrase not in vocab_data["categories"][category]:
                vocab_data["categories"][category].append(phrase)
        print(f"âœ… å·²æ–°å¢: {phrase}")
        if category:
            print(f"   åˆ†é¡: {category}")
    else:
        print(f"âš ï¸  è©å½™å·²å­˜åœ¨: {phrase}")

def remove_phrase(vocab_data, phrase):
    """ç§»é™¤è©å½™"""
    if phrase in vocab_data["phrases"]:
        vocab_data["phrases"].remove(phrase)
        # å¾åˆ†é¡ä¸­ç§»é™¤
        for category in vocab_data["categories"]:
            if phrase in vocab_data["categories"][category]:
                vocab_data["categories"][category].remove(phrase)
        print(f"âœ… å·²ç§»é™¤: {phrase}")
    else:
        print(f"âŒ è©å½™ä¸å­˜åœ¨: {phrase}")

def list_vocabulary(vocab_data):
    """é¡¯ç¤ºæ‰€æœ‰è©å½™"""
    print("\nğŸ“š è‡ªå®šç¾©è©å½™åº«:")
    print("=" * 50)
    
    if not vocab_data["phrases"]:
        print("âŒ è©å½™åº«ç‚ºç©º")
        return
    
    print(f"ğŸ“Š ç¸½å…± {len(vocab_data['phrases'])} å€‹è©å½™")
    if vocab_data["last_updated"]:
        print(f"ğŸ•’ æœ€å¾Œæ›´æ–°: {vocab_data['last_updated']}")
    print()
    
    # æŒ‰åˆ†é¡é¡¯ç¤º
    if vocab_data["categories"]:
        for category, phrases in vocab_data["categories"].items():
            if phrases:
                print(f"ğŸ“ {category}:")
                for phrase in phrases:
                    print(f"   â€¢ {phrase}")
                print()
    
    # é¡¯ç¤ºæœªåˆ†é¡çš„è©å½™
    categorized_phrases = set()
    for phrases in vocab_data["categories"].values():
        categorized_phrases.update(phrases)
    
    uncategorized = [p for p in vocab_data["phrases"] if p not in categorized_phrases]
    if uncategorized:
        print("ğŸ“ æœªåˆ†é¡:")
        for phrase in uncategorized:
            print(f"   â€¢ {phrase}")

def add_predefined_phrases(vocab_data):
    """æ–°å¢ä¸€äº›å¸¸è¦‹çš„å°ˆæ¥­è¡“èªç¯„ä¾‹"""
    # æŠ€è¡“ç›¸é—œ
    tech_phrases = [
        "API", "SDK", "REST API", "GraphQL", "OAuth", "JWT",
        "Docker", "Kubernetes", "microservices", "DevOps",
        "machine learning", "artificial intelligence", "neural network",
        "deep learning", "computer vision", "natural language processing",
        "TensorFlow", "PyTorch", "scikit-learn", "pandas", "NumPy"
    ]
    
    # å•†æ¥­ç›¸é—œ
    business_phrases = [
        "KPI", "ROI", "SaaS", "B2B", "B2C", "CRM", "ERP",
        "scalability", "monetization", "MVP", "proof of concept",
        "user experience", "user interface", "agile development"
    ]
    
    # Google Cloud ç›¸é—œ
    gcp_phrases = [
        "Google Cloud", "BigQuery", "Cloud Storage", "Cloud Run",
        "App Engine", "Compute Engine", "Cloud Functions",
        "Firestore", "Cloud SQL", "Pub Sub", "Cloud Vision",
        "Speech to Text", "Cloud Translation"
    ]
    
    print("ğŸ“¦ æ–°å¢é è¨­å°ˆæ¥­è¡“èª...")
    
    for phrase in tech_phrases:
        add_phrase(vocab_data, phrase, "æŠ€è¡“")
    
    for phrase in business_phrases:
        add_phrase(vocab_data, phrase, "å•†æ¥­")
        
    for phrase in gcp_phrases:
        add_phrase(vocab_data, phrase, "Google Cloud")
    
    print(f"âœ… å·²æ–°å¢ {len(tech_phrases + business_phrases + gcp_phrases)} å€‹é è¨­è¡“èª")

def interactive_mode():
    """äº’å‹•æ¨¡å¼"""
    vocab_data = load_vocabulary()
    
    while True:
        print("\nğŸ¯ è‡ªå®šç¾©è©å½™ç®¡ç†")
        print("=" * 30)
        print("1. ğŸ“ æ–°å¢è©å½™")
        print("2. ğŸ—‘ï¸  ç§»é™¤è©å½™") 
        print("3. ğŸ“š æŸ¥çœ‹è©å½™åº«")
        print("4. ğŸ“¦ æ–°å¢é è¨­è¡“èª")
        print("5. ğŸ“¤ åŒ¯å‡ºè©å½™")
        print("6. ğŸ“¥ åŒ¯å…¥è©å½™")
        print("7. ğŸš€ æ¸¬è©¦è­˜åˆ¥")
        print("0. é€€å‡º")
        
        choice = input("\nè«‹é¸æ“‡ (0-7): ").strip()
        
        if choice == "1":
            phrase = input("è¼¸å…¥è©å½™: ").strip()
            if phrase:
                category = input("è¼¸å…¥åˆ†é¡ (å¯é¸): ").strip() or None
                add_phrase(vocab_data, phrase, category)
                save_vocabulary(vocab_data)
        
        elif choice == "2":
            phrase = input("è¼¸å…¥è¦ç§»é™¤çš„è©å½™: ").strip()
            if phrase:
                remove_phrase(vocab_data, phrase)
                save_vocabulary(vocab_data)
        
        elif choice == "3":
            list_vocabulary(vocab_data)
        
        elif choice == "4":
            add_predefined_phrases(vocab_data)
            save_vocabulary(vocab_data)
        
        elif choice == "5":
            export_file = input("åŒ¯å‡ºæª”å (é è¨­: vocabulary_export.txt): ").strip() or "vocabulary_export.txt"
            with open(export_file, 'w', encoding='utf-8') as f:
                for phrase in vocab_data["phrases"]:
                    f.write(phrase + "\n")
            print(f"âœ… å·²åŒ¯å‡ºåˆ° {export_file}")
        
        elif choice == "6":
            import_file = input("åŒ¯å…¥æª”å: ").strip()
            if os.path.exists(import_file):
                with open(import_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                for line in lines:
                    phrase = line.strip()
                    if phrase:
                        add_phrase(vocab_data, phrase)
                save_vocabulary(vocab_data)
            else:
                print("âŒ æª”æ¡ˆä¸å­˜åœ¨")
        
        elif choice == "7":
            print("ğŸš€ å•Ÿå‹•å¸¶è‡ªå®šç¾©è©å½™çš„èªéŸ³è­˜åˆ¥...")
            break
        
        elif choice == "0":
            break
        
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡")

def get_phrases_for_recognition():
    """ç²å–ç”¨æ–¼èªéŸ³è­˜åˆ¥çš„è©å½™åˆ—è¡¨"""
    vocab_data = load_vocabulary()
    return vocab_data["phrases"]

if __name__ == "__main__":
    interactive_mode() 